# 第1关 | 书生大模型全链路开源开放体系

## 任务

> [task.md](https://github.com/InternLM/Tutorial/blob/camp3/docs/L1/HelloIntern/task.md)

观看本关卡视频（未上传制作中）后，写一篇关于书生大模型全链路开源开放体系的笔记发布到知乎、CSDN等任一社交媒体，将作业链接提交到以下问卷，助教老师批改后将获得 100 算力点奖励！！！

提交地址：<https://aicarrier.feishu.cn/share/base/form/shrcnZ4bQ4YmhEtMtnKxZUcf1vd>

## 文档

> [readme.md](https://github.com/InternLM/Tutorial/blob/camp3/docs/L1/HelloIntern/readme.md)

[【B站】书生·浦语大模型全链路开源开放体系](https://www.bilibili.com/video/BV18142187g5/)

## 作业

书生·浦语大模型全链路开源开放体系
> 介绍了书生·浦语大模型及其工具链

![0-1书生·浦语大模型全链路开源开放体系](vx_images/0-1书生·浦语大模型全链路开源开放体系.png)

### 发展史

![0-2发展史](vx_images/0-2发展史.png)
![0-3书生性能天梯](vx_images/0-3书生性能天梯.png)
![0-4书生·浦语2.5概览](vx_images/0-4书生·浦语2.5概览.png)

### 核心技术思路

![0-5核心技术思路](vx_images/0-5核心技术思路.png)

![0-6高质量合成数据](vx_images/0-6高质量合成数据.png)

![0-7领先的推理能力](vx_images/0-7领先的推理能力.png)

![0-8大海捞针实验](vx_images/0-8大海捞针实验.png)

![0-9基于规划和搜索解决复杂问题](vx_images/0-9基于规划和搜索解决复杂问题.png)

### 全链条开源开放体系

![0-10全链条开源](vx_images/0-10全链条开源.png)

![0-11数据](vx_images/0-11数据.png)

![0-12开源数据处理工具箱](vx_images/0-12开源数据处理工具箱.png)

![0-13预训练InternEvo](vx_images/0-13预训练InternEvo.png)

![0-14微调XTuner](vx_images/0-14微调XTuner.png)

![0-15微调XTuner](vx_images/0-15微调XTuner.png)

![0-16微调XTuner](vx_images/0-16微调XTuner.png)

![0-17OpenCompass评测体系](vx_images/0-17OpenCompass评测体系.png)

![0-18OpenCompass评测体系](vx_images/0-18OpenCompass评测体系.png)

![0-19OpenCompass评测体系](vx_images/0-19OpenCompass评测体系.png)

![1-20部署LMDeploy](vx_images/1-20部署LMDeploy.png)

![1-21部署LMDeploy](vx_images/1-21部署LMDeploy.png)

![1-22智能体](vx_images/1-22智能体.png)

![1-23智能体](vx_images/1-23智能体.png)

![1-24智能体MindSearch](vx_images/1-24智能体MindSearch.png)

![1-25企业级知识库构建工具](vx_images/1-25企业级知识库构建工具.png)

![1-26企业级知识库构建工具](vx_images/1-26企业级知识库构建工具.png)

![1-27全链条开源](vx_images/1-27全链条开源.png)

数据质量驱动模型性能

### 总结

#### 模型说明

> 目前 InternLM 2.5 系列发布了 1.8B、7B 和 20B 大小的模型  

1. InternLM2.5：经历了大规模预训练的基座模型，是我们推荐的在大部分应用中考虑选用的优秀基座。
2. InternLM2.5-Chat: 对话模型，在 InternLM2.5 基座上经历了有监督微调和 online RLHF。InternLM2.5-Chat 面向对话交互进行了优化，具有较好的指令遵循、共情聊天和调用工具等的能力，是我们推荐直接用于下游应用的模型。
3. InternLM2.5-Chat-1M: InternLM2.5-Chat-1M 支持一百万字超长上下文，并具有和 InternLM2.5-Chat 相当的综合性能表现。

#### 要点

- 🌟 InternLM2模型，1.8B参数，轻量化，适用于个人开发机。
- 💻 使用InterStudio创建开发环境，实现模型训练和部署。
- 🔎 自由文本图像组合模型，解决复杂视觉语言问题。
- 🎈 LMDeploy支持模型压缩、量化、分发，兼容性好。
- 📡 Web demo利用streamlit，轻松展示模型效果。
- 🌈 InternVL2（书生-万象）模型，综合性能媲美国际闭源商业模型，支持多种模态。
- 🖼️ 图文理解对话功能，演示上传图像和指令输入，体验模型理解能力。
- 🌐 LMDeploy 支持TurboMind 引擎和 PyTorch 引擎模型部署。
- 📝 输入指令和文本，模型即时反馈，展示语言处理效果。
- 🌟 全链条开源，数据，预训练，微调，部署，评测，应用等全面开源。

#### 视频总结

- 模型发展：介绍了InternLM2.5的最新版本及其在推理能力、上下文支持和自主规划等方面的提升。  
- 数据处理：描述了数据提取和标注工具，如Miner U和Label LLM。  
- 预训练和微调：InternEvo和XTuner分别在预训练和微调方面的优势。  
- 评测和部署：OpenCompass评测体系和LMDeploy部署工具的特点和优势。  
- 智能体：MindSearch智能体和智能体MindSearch的介绍。
- 企业级知识库：企业级知识库构建工具的介绍。  
- 全链条开源：全链条开源体系的优势和特点。
